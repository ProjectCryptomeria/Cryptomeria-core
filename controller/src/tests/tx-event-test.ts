import { stringToPath } from '@cosmjs/crypto';
import { AccountData, DirectSecp256k1HdWallet, EncodeObject, GeneratedType, Registry } from '@cosmjs/proto-signing';
import { calculateFee, GasPrice, SigningStargateClient } from '@cosmjs/stargate';
// â˜… ä¿®æ­£ç‚¹1: TxEvent ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
import { Comet38Client, WebsocketClient } from "@cosmjs/tendermint-rpc";
import { TxEvent } from "@cosmjs/tendermint-rpc/build/comet38/responses"; // â˜… æ˜ç¤ºçš„ãªãƒ‘ã‚¹
import { Listener, Stream } from "xstream";

import { sleep } from "@cosmjs/utils";
import * as k8s from '@kubernetes/client-node';
import { TxRaw } from 'cosmjs-types/cosmos/tx/v1beta1/tx';
import * as fs from 'fs';
import * as path from 'path';
import { Writer } from 'protobufjs/minimal';
import winston from 'winston';
import Transport from 'winston-transport';
// ä¿®æ­£ç‚¹4: ä¸è¦ãª Subscription ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å‰Šé™¤

// =================================================================================================
// ğŸ“š I. CONFIG & TYPE DEFINITIONS (å¤‰æ›´ãªã—)
// =================================================================================================
const CONFIG = { /* ... (å¤‰æ›´ãªã—) ... */
	K8S_NAMESPACE: 'raidchain',
	SECRET_NAME: 'raidchain-mnemonics',
	GAS_PRICE_STRING: '0.0000001uatom',
	GAS_MULTIPLIER: 1.5,
	HD_PATH: "m/44'/118'/0'/0/2",
	TARGET_CHAIN_NAME: 'data-0',
	NUM_TRANSACTIONS: 100,
	DATA_SIZE_BYTES: 50 * 1024,
	TX_EVENT_TIMEOUT_MS: 60000,
	WEBSOCKET_CONNECT_TIMEOUT_MS: 5000,
	RECONNECT_DELAY_MS: 3000,
};
interface TransformableInfo extends winston.Logform.TransformableInfo { level: string; message: string;[key: string]: any; }
interface ChainInfo { name: string; type: 'datachain' | 'metachain'; }
interface ExtendedChainClients {
	client: SigningStargateClient;
	account: AccountData;
	tmClient: Comet38Client; // â˜… ä¿®æ­£
	wsClient: WebsocketClient;
}
interface MsgCreateStoredChunk { creator: string; index: string; data: Uint8Array; }
const MsgCreateStoredChunkProto = { /* ... (å¤‰æ›´ãªã—) ... */
	create(base?: Partial<MsgCreateStoredChunk>): MsgCreateStoredChunk { return { creator: base?.creator ?? "", index: base?.index ?? "", data: base?.data ?? new Uint8Array(), }; },
	encode(message: MsgCreateStoredChunk, writer: Writer = Writer.create()): Writer {
		if (message.creator !== '') { writer.uint32(10).string(message.creator); }
		if (message.index !== '') { writer.uint32(18).string(message.index); }
		if (message.data.length !== 0) { writer.uint32(26).bytes(message.data); }
		return writer;
	},
	decode(input: import("protobufjs").Reader | Uint8Array, length?: number | undefined): MsgCreateStoredChunk { throw new Error("Method not implemented."); } // decodeã¯çœç•¥
};
const customRegistry = new Registry([
	['/datachain.datastore.v1.MsgCreateStoredChunk', MsgCreateStoredChunkProto as GeneratedType],
]);

// =================================================================================================
// ğŸ“ II. LOGGER UTILITIES (å¤‰æ›´ãªã—)
// =================================================================================================
class LoggerUtil { /* ... (å¤‰æ›´ãªã—) ... */
	private readonly logBuffer: TransformableInfo[] = [];
	private readonly logger: winston.Logger;
	private readonly logFilePath: string;

	constructor() {
		const scriptFileName = path.basename(process.argv[1]!).replace(path.extname(process.argv[1]!), '');
		// Ensure directory exists synchronously before logger creation
		const logDir = path.join(process.cwd(), "src/tests/");
		try {
			if (!fs.existsSync(logDir)) {
				fs.mkdirSync(logDir, { recursive: true });
			}
		} catch (e) {
			console.error(`Error creating log directory ${logDir}:`, e);
		}
		this.logFilePath = path.join(logDir, `${scriptFileName}.log`);


		class LogBufferTransport extends Transport {
			private readonly buffer: TransformableInfo[];
			constructor(buffer: TransformableInfo[], opts?: Transport.TransportStreamOptions) {
				super(opts);
				this.buffer = buffer;
			}
			log(info: any, callback: () => void) {
				setImmediate(() => { this.emit('logged', info); });
				this.buffer.push(info);
				callback();
			}
		}

		this.logger = winston.createLogger({
			level: 'info',
			format: winston.format.combine(
				winston.format.timestamp({ format: 'YYYY-MM-DDTHH:mm:ss.SSSZ' }),
				winston.format.printf(info => `[${info.timestamp}] [${info.level.toUpperCase()}] - ${info.message} ${info.stack ? '\n' + info.stack : ''}`)
			),
			transports: [
				new LogBufferTransport(this.logBuffer),
				new winston.transports.Console({
					format: winston.format.combine(
						winston.format.timestamp({ format: 'HH:mm:ss' }),
						winston.format.printf(info => `[${info.timestamp}] [${info.level.toUpperCase()}] - ${info.message}`)
					)
				})
			],
		});
	}

	public getLogger(): winston.Logger {
		return this.logger;
	}

	public async flushLogs() {
		if (this.logBuffer.length === 0) return;
		// Ensure directory exists before writing
		const logDir = path.dirname(this.logFilePath);
		try {
			await fs.promises.mkdir(logDir, { recursive: true });
		} catch (e) {
			console.error(`Error ensuring log directory ${logDir} exists:`, e);
			// Continue trying to write the log file anyway
		}

		const logContent = this.logBuffer
			.map(info => {
				const transformed = this.logger.format.transform(info, {});
				return transformed && (transformed as TransformableInfo).message && info.level !== 'info' ? (transformed as TransformableInfo).message : '';
			})
			.filter(line => line.length > 0)
			.join('\n');
		try {
			await fs.promises.writeFile(this.logFilePath, logContent + '\n', { flag: 'w' });
			console.error(`\nğŸš¨ ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿ã¾ã—ãŸ: ${this.logFilePath}`);
		} catch (e) {
			console.error('ERROR: Failed to write logs to file.', e);
		}
	}
}
const loggerUtil = new LoggerUtil();
const logger = loggerUtil.getLogger();

// =================================================================================================
// ğŸ’» III. KUBERNETES UTILITIES (å¤‰æ›´ãªã—)
// =================================================================================================
const kc = new k8s.KubeConfig();
kc.loadFromDefault();
const k8sApi = kc.makeApiClient(k8s.CoreV1Api);

async function getRpcWsEndpoint(targetChainName: string): Promise<string> { /* ... (å¤‰æ›´ãªã—) ... */
	let rpcEndpointHttp = '';
	const isLocal = process.env.NODE_ENV !== 'production';

	try {
		logger.info(`Fetching RPC endpoint for chain "${targetChainName}"...`);
		const resServices = await k8sApi.listNamespacedService({
			namespace: CONFIG.K8S_NAMESPACE,
			labelSelector: `app.kubernetes.io/instance=${targetChainName}`
		});
		const serviceName = `raidchain-${targetChainName}-headless`;
		const service = resServices.items.find(s => s.metadata?.name === serviceName);

		if (!service) throw new Error(`Service "${serviceName}" not found.`);

		if (isLocal) {
			const rpcPortInfo = service?.spec?.ports?.find(p => p.name === 'rpc');
			if (rpcPortInfo?.nodePort) {
				rpcEndpointHttp = `http://localhost:${rpcPortInfo.nodePort}`;
			} else {
				throw new Error(`RPC NodePort not found for service "${serviceName}".`);
			}
		} else {
			const podHostName = `raidchain-${targetChainName}-0`;
			const headlessServiceName = `raidchain-chain-headless`;
			rpcEndpointHttp = `http://${podHostName}.${headlessServiceName}.${CONFIG.K8S_NAMESPACE}.svc.cluster.local:26657`;
		}

		if (!rpcEndpointHttp) throw new Error(`Could not determine RPC endpoint.`);

		const rpcEndpointWs = rpcEndpointHttp.replace('http', 'ws'); // HTTP -> WS
		logger.info(`âœ… WebSocket RPC endpoint found: ${rpcEndpointWs}`);
		return rpcEndpointWs;

	} catch (err) {
		logger.error(`Failed to get RPC endpoint for "${targetChainName}".`);
		if (err instanceof Error) logger.error(`   Error: ${err.message}`);
		else logger.error(`   Unknown error: ${err}`);
		throw err;
	}
}
async function getCreatorMnemonic(chainName: string): Promise<string> { /* ... (å¤‰æ›´ãªã—) ... */
	const res = await k8sApi.readNamespacedSecret({
		name: CONFIG.SECRET_NAME,
		namespace: CONFIG.K8S_NAMESPACE,
	});
	const encodedMnemonic = res.data?.[`${chainName}.mnemonic`];
	if (!encodedMnemonic) throw new Error(`Secret does not contain mnemonic for ${chainName}.`);
	return Buffer.from(encodedMnemonic, 'base64').toString('utf-8');
}

// =================================================================================================
// ğŸš€ IV. CHAIN CLIENT & TRANSACTION MANAGEMENT (ä¿®æ­£ã‚ã‚Š)
// =================================================================================================
class ChainManager {
	private chainClientInfo: ExtendedChainClients | null = null;
	public readonly gasPrice: GasPrice;
	private wsUrl: string = '';

	constructor() {
		this.gasPrice = GasPrice.fromString(CONFIG.GAS_PRICE_STRING);
	}

	public async initializeClient(wsUrl: string): Promise<void> {
		this.wsUrl = wsUrl;
		const chainName = CONFIG.TARGET_CHAIN_NAME;
		try {
			const mnemonic = await getCreatorMnemonic(chainName);
			const wallet = await DirectSecp256k1HdWallet.fromMnemonic(mnemonic, { hdPaths: [stringToPath(CONFIG.HD_PATH)] });
			const [account] = await wallet.getAccounts();
			if (!account) throw new Error(`Failed to get account from wallet`);

			const wsClient = new WebsocketClient(wsUrl, (err) => {
				logger.error(` WebSocket error: ${err?.message || err}. Attempting reconnect...`);
				this.reconnectClient();
			});

			// â˜… ä¿®æ­£ç‚¹5: connect() -> connected()
			const connectPromise = wsClient.execute({ jsonrpc: "2.0", method: "status", id: 1, params: [] }); // æ¥ç¶šç¢ºèª
			const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error("WebSocket connection timed out")), CONFIG.WEBSOCKET_CONNECT_TIMEOUT_MS));
			await Promise.race([connectPromise, timeoutPromise]);

			// â˜… ä¿®æ­£ç‚¹1: CometBFTClient -> Comet38Client
			const tmClient = Comet38Client.create(wsClient);
			const client = SigningStargateClient.createWithSigner(tmClient, wallet, { registry: customRegistry, gasPrice: this.gasPrice });

			this.chainClientInfo = { client, account, tmClient, wsClient };
			logger.info(`[CLIENT_SETUP] Successful for chain: ${chainName} (Address: ${account.address})`);
		} catch (e) {
			logger.error(`[CLIENT_SETUP] Failed to initialize client for chain ${chainName}:`, e);
			if (this.chainClientInfo?.wsClient) {
				this.chainClientInfo.wsClient.disconnect();
			}
			this.chainClientInfo = null;
			throw e;
		}
	}

	// reconnectClient (å¤‰æ›´ãªã—)
	private async reconnectClient(): Promise<void> { /* ... (å¤‰æ›´ãªã—) ... */
		if (!this.wsUrl) return; // URL ãŒãªã‘ã‚Œã°ä½•ã‚‚ã—ãªã„
		logger.info(`Attempting to reconnect in ${CONFIG.RECONNECT_DELAY_MS}ms...`);
		await sleep(CONFIG.RECONNECT_DELAY_MS);
		try {
			await this.initializeClient(this.wsUrl);
		} catch (error) {
			logger.error("Reconnection failed:", error);
			// ã•ã‚‰ã«å¾…æ©Ÿã—ã¦å†è©¦è¡Œ
			this.reconnectClient();
		}
	}

	public getClientInfo(): ExtendedChainClients {
		if (!this.chainClientInfo) throw new Error(`Client not initialized`);
		return this.chainClientInfo;
	}

	// broadcastSequentialTxs (å¤‰æ›´ãªã—)
	public async broadcastSequentialTxs(messages: EncodeObject[], estimatedGas: number): Promise<string[]> { /* ... (å¤‰æ›´ãªã—) ... */
		const { client, account } = this.getClientInfo();
		const gasWanted = Math.round(estimatedGas * CONFIG.GAS_MULTIPLIER);
		const fee = calculateFee(gasWanted, this.gasPrice);
		const totalTxs = messages.length;

		const accountInfo = await client.getAccount(account.address);
		if (!accountInfo) throw new Error(`Failed to get account info`);

		let currentSequence = accountInfo.sequence;
		const accountNumber = accountInfo.accountNumber;
		const chainId = await client.getChainId();

		logger.info(`[SEQ_BROADCAST] Starting sequence: ${currentSequence}, Total Txs: ${totalTxs}.`);
		const txHashes: string[] = [];

		for (let i = 0; i < totalTxs; i++) {
			const msg = messages[i]!;
			const signedTx = await client.sign(
				account.address, [msg], fee, `Tx ${i + 1}/${totalTxs} (Seq: ${currentSequence})`,
				{ accountNumber, sequence: currentSequence, chainId }
			);
			const txRaw = Uint8Array.from(TxRaw.encode(signedTx).finish());

			try {
				const resultHash = await client.broadcastTxSync(txRaw);
				txHashes.push(resultHash);
				logger.info(` -> Tx ${i + 1} sent. Hash: ${resultHash.substring(0, 10)}... (Seq: ${currentSequence})`);
			} catch (error) {
				logger.error(`[CRITICAL_FAIL] Failed to broadcast Tx ${i + 1}. Error:`, error);
				// ä¸€éƒ¨å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œã™ã‚‹ãŒã€ãƒãƒƒã‚·ãƒ¥ã¯è¨˜éŒ²ã—ã¦ãŠã
				txHashes.push(`ERROR_BROADCASTING_TX_${i + 1}`);
			}
			currentSequence++;
		}
		logger.info(`[SEQ_BROADCAST] Finished broadcasting ${totalTxs} transactions.`);
		return txHashes;
	}

	// closeConnection (å¤‰æ›´ãªã—)
	public closeConnection(): void { /* ... (å¤‰æ›´ãªã—) ... */
		if (this.chainClientInfo?.wsClient) {
			this.chainClientInfo.wsClient.disconnect();
			logger.info(`[CLEANUP] WebSocket connection closed.`);
		}
		this.chainClientInfo = null;
	}
}

// =================================================================================================
// âš™ï¸ V. CORE LOGIC (Txã‚¤ãƒ™ãƒ³ãƒˆç›£è¦– - ä¿®æ­£ã‚ã‚Š)
// =================================================================================================

// waitForTxInclusionWithEvents é–¢æ•°ã®å†…å®¹ã‚’ç½®ãæ›ãˆ

/**
 * æŒ‡å®šã•ã‚ŒãŸTxãƒãƒƒã‚·ãƒ¥ãƒªã‚¹ãƒˆã®å®Œäº†ã‚’Txã‚¤ãƒ™ãƒ³ãƒˆã§ç›£è¦–ã™ã‚‹ (å˜ä¸€è³¼èª­ç‰ˆ)
 */
async function waitForTxInclusionWithEvents(tmClient: Comet38Client, targetHashes: string[]): Promise<Map<string, boolean>> {
	const confirmationStatus = new Map<string, boolean>();
	// â˜… å¾…æ©Ÿå¯¾è±¡ã®ãƒãƒƒã‚·ãƒ¥ã‚’ Set ã«å…¥ã‚Œã¦åŠ¹ç‡åŒ–
	const targetHashSet = new Set<string>();
	targetHashes.forEach(hash => {
		confirmationStatus.set(hash, false);
		if (!hash.startsWith("ERROR_BROADCASTING")) {
			targetHashSet.add(hash.toUpperCase()); // å¤§æ–‡å­—ã§æ¯”è¼ƒã™ã‚‹ãŸã‚
		}
	});

	let confirmedCount = 0;
	const expectedConfirmations = targetHashSet.size; // å®Ÿéš›ã«å¾…ã¤ã¹ãæ•°

	// â˜… ãƒªã‚¹ãƒŠãƒ¼ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’1ã¤ã ã‘ç®¡ç†
	let stream: Stream<TxEvent> | null = null;
	let listener: Listener<TxEvent> | null = null;
	let timeoutId: NodeJS.Timeout | null = null;

	return new Promise((resolve, reject) => {

		const cleanup = () => {
			if (timeoutId) clearTimeout(timeoutId);
			// â˜… å˜ä¸€ã®ãƒªã‚¹ãƒŠãƒ¼ã‚’è§£é™¤
			if (stream && listener) {
				try {
					stream.removeListener(listener);
					logger.info("[EVENT_WAIT] Cleaned up the listener.");
				} catch (e) {
					logger.warn("Error removing listener (ignoring):", e);
				}
			}
			stream = null;
			listener = null;
		};

		timeoutId = setTimeout(() => {
			cleanup();
			const unconfirmed = Array.from(confirmationStatus.entries())
				.filter(([hash, confirmed]) => targetHashSet.has(hash.toUpperCase()) && !confirmed) // å¾…æ©Ÿå¯¾è±¡ã®ã¿
				.map(([hash, _]) => hash.substring(0, 10) + "...");
			logger.error(`[EVENT_WAIT] Timeout after ${CONFIG.TX_EVENT_TIMEOUT_MS}ms. ${confirmedCount}/${expectedConfirmations} confirmed.`);
			logger.error(` Unconfirmed: ${unconfirmed.join(', ')}`);
			reject(new Error(`Timeout waiting for Tx events. Only ${confirmedCount}/${expectedConfirmations} confirmed.`));
		}, CONFIG.TX_EVENT_TIMEOUT_MS);

		// --- â˜… å˜ä¸€ã®ã‚¤ãƒ™ãƒ³ãƒˆè³¼èª­ ---
		const query = `tm.event = 'Tx'`;
		stream = tmClient.subscribeTx(query) as Stream<TxEvent>; // å‹ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³

		listener = {
			next: (event: TxEvent) => {
				const receivedHash = Buffer.from(event.hash).toString("hex").toUpperCase();

				// å¾…æ©Ÿä¸­ã®ãƒãƒƒã‚·ãƒ¥ã«å«ã¾ã‚Œã¦ã„ã¦ã€ã¾ã ç¢ºèªã•ã‚Œã¦ã„ãªã‘ã‚Œã°å‡¦ç†
				if (targetHashSet.has(receivedHash) && confirmationStatus.get(receivedHash) === false) {
					const success = event.result.code === 0;
					logger.info(`[EVENT_RECV] Tx ${receivedHash.substring(0, 10)}... confirmed in block ${event.height}. Success: ${success}`);
					confirmationStatus.set(receivedHash, success); // ãƒãƒƒã‚·ãƒ¥ã‚’ã‚­ãƒ¼ã«ã—ã¦çµæœã‚’ä¿å­˜
					confirmedCount++;

					// å…¨ã¦ã®å¾…æ©Ÿå¯¾è±¡ãŒç¢ºèªã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
					if (confirmedCount === expectedConfirmations) {
						logger.info(`[EVENT_WAIT] All ${confirmedCount} expected transactions confirmed.`);
						cleanup();
						resolve(confirmationStatus);
					}
				}
				// å¾…æ©Ÿå¯¾è±¡å¤–ã®Txã‚¤ãƒ™ãƒ³ãƒˆã¯ç„¡è¦–
			},
			error: (err: any) => {
				logger.error(`[EVENT_ERROR] Error in the main Tx subscription stream:`, err);
				cleanup(); // ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯è³¼èª­ã‚’ä¸­æ­¢
				reject(err); // Promiseã‚’å¤±æ•—ã•ã›ã‚‹
			},
			complete: () => {
				logger.warn(`[EVENT_COMPLETE] Main Tx subscription stream completed unexpectedly.`);
				// ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒäºˆæœŸã›ãšçµ‚äº†ã—ãŸå ´åˆã€æœªå®Œäº†ãªã‚‰å¤±æ•—ã¨ã™ã‚‹
				if (confirmedCount < expectedConfirmations) {
					reject(new Error("Subscription stream ended before all transactions were confirmed."));
				}
				cleanup();
			},
		};

		stream.addListener(listener);
		logger.info(`[EVENT_SUB] Subscribed to all Tx events.`);
		// --- â˜… å˜ä¸€è³¼èª­ã“ã“ã¾ã§ ---

		// ã‚³ãƒ¼ãƒŠãƒ¼ã‚±ãƒ¼ã‚¹
		if (expectedConfirmations === 0 && targetHashes.length > 0) {
			logger.warn("[EVENT_WAIT] No transactions to wait for (all failed broadcasting?).");
			cleanup();
			resolve(confirmationStatus);
		} else if (targetHashes.length === 0) {
			logger.info("[EVENT_WAIT] No transactions were sent.");
			cleanup();
			resolve(confirmationStatus);
		}

	}); // return new Promise
}

// =================================================================================================
// ğŸš€ MAIN EXECUTION (å¤‰æ›´ãªã—)
// =================================================================================================
async function main() {
	const chainManager = new ChainManager();
	const startTime = Date.now();

	try {
		// ... (ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆã€ã‚¬ã‚¹è¦‹ç©ã‚‚ã‚Šã€é€ä¿¡ã¯å¤‰æ›´ãªã—) ...
		// 1. WebSocketã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå–å¾— & ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
		const wsUrl = await getRpcWsEndpoint(CONFIG.TARGET_CHAIN_NAME);
		await chainManager.initializeClient(wsUrl);
		const { client, account, tmClient } = chainManager.getClientInfo(); // tmClient ã‚‚å–å¾—

		// 2. é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
		logger.info(`Preparing ${CONFIG.NUM_TRANSACTIONS} transactions...`);
		const messages: EncodeObject[] = [];
		const uniqueSuffix = `tx-event-test-${Date.now()}`;

		logger.info("Starting message creation loop..."); // â˜… è¿½åŠ ãƒ­ã‚°1

		for (let i = 0; i < CONFIG.NUM_TRANSACTIONS; i++) {
			const index = `${uniqueSuffix}-${i}`;
			// logger.info(`Creating message ${i + 1}`); // å¿…è¦ãªã‚‰ãƒ«ãƒ¼ãƒ—å†…ã«ã‚‚ãƒ­ã‚°ã‚’è¿½åŠ 
			const data = Buffer.alloc(CONFIG.DATA_SIZE_BYTES, `Data for ${index}`);
			messages.push({
				typeUrl: '/datachain.datastore.v1.MsgCreateStoredChunk',
				value: { creator: account.address, index: index, data: data },
			});
		}

		logger.info(`Finished message creation loop. ${messages.length} messages created.`); // â˜… è¿½åŠ ãƒ­ã‚°2

		// 3. ã‚¬ã‚¹ä»£ã®è¦‹ç©ã‚‚ã‚Š (æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨)
		const dummyMsg = messages[0]!;
		if (!dummyMsg) {
			throw new Error("No messages were created, cannot simulate gas.");
		}

		logger.info("Simulating gas for the first transaction..."); // â˜… è¿½åŠ ãƒ­ã‚°3
		const estimatedGas = await client.simulate(account.address, [dummyMsg], 'Gas Estimation');
		// â†“ å…ƒã®æ¬¡ã®ãƒ­ã‚°
		logger.info(`[GAS_SIMULATE] Estimated gas: ${estimatedGas}. Gas Wanted: ${Math.round(estimatedGas * CONFIG.GAS_MULTIPLIER)}.`);

		// 4. ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€£ç¶šé€ä¿¡
		logger.info(`Broadcasting ${CONFIG.NUM_TRANSACTIONS} transactions...`);
		const txHashes = await chainManager.broadcastSequentialTxs(messages, estimatedGas);
		const broadcastEndTime = Date.now();
		logger.info(`Broadcasting finished in ${(broadcastEndTime - startTime) / 1000}s.`);

		// 5. Txã‚¤ãƒ™ãƒ³ãƒˆã§å®Œäº†ã‚’å¾…æ©Ÿ (tmClient ã‚’æ¸¡ã™)
		logger.info(`Waiting for ${txHashes.filter(h => !h.startsWith("ERROR_BROADCASTING")).length} transactions inclusion via Tx events (Timeout: ${CONFIG.TX_EVENT_TIMEOUT_MS / 1000}s)...`);
		const confirmationResults = await waitForTxInclusionWithEvents(tmClient, txHashes); // tmClient ã‚’ä½¿ç”¨
		const confirmationEndTime = Date.now();


		// ... (çµæœé›†è¨ˆã€çµ‚äº†å‡¦ç†ã¯å¤‰æ›´ãªã—) ...
		// 6. çµæœé›†è¨ˆ
		let successCount = 0;
		let broadcastFailCount = 0;
		let executionFailCount = 0; // ã‚¤ãƒ™ãƒ³ãƒˆã¯æ¥ãŸãŒå®Ÿè¡Œå¤±æ•— or ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
		confirmationResults.forEach((confirmedAndSuccess, hash) => {
			if (hash.startsWith("ERROR_BROADCASTING")) {
				broadcastFailCount++;
			} else if (confirmedAndSuccess === true) {
				successCount++;
			} else { // confirmedAndSuccess ãŒ false
				executionFailCount++;
			}
		});

		logger.info('\n--- Test Summary ---');
		logger.info(`Total Transactions Sent Attempted: ${CONFIG.NUM_TRANSACTIONS}`);
		logger.info(`Successfully Broadcast & Executed: ${successCount}`);
		logger.info(`Broadcast Failures: ${broadcastFailCount}`);
		logger.info(`Execution Failures or Timeout: ${executionFailCount}`);
		logger.info(`Total Time: ${(confirmationEndTime - startTime) / 1000} seconds`);
		logger.info(`  (Broadcasting: ${(broadcastEndTime - startTime) / 1000}s, Confirmation: ${(confirmationEndTime - broadcastEndTime) / 1000}s)`);

		// ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå¤±æ•— + å®Ÿè¡Œå¤±æ•— + ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ãŒ0ä»¶ã®å ´åˆã®ã¿æˆåŠŸ
		if (executionFailCount > 0 || broadcastFailCount > 0) {
			throw new Error("Test finished with failures.");
		}

		logger.info("âœ… Test completed successfully!");


	} catch (err) {
		logger.error('[MAIN] A fatal error occurred:', err);
		throw err;
	} finally {
		chainManager.closeConnection();
		await loggerUtil.flushLogs();
	}
}

// å®Ÿè¡Œ
main().then(() => {
	process.exit(0);
}).catch(err => {
	console.error("Test script failed:", err);
	process.exit(1);
});
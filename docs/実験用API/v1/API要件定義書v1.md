# Cryptomeria-BFF API 要件定義書（仕様書の仕様書）
Version: v1（Draft）  
対象：Cryptomeria-core（k8s/helm/relayer/chain群） + Cryptomeria-BFF（API化）  
成果物：第1層（System/K8s）・第2層（Blockchain）・第3層（Utilities） API仕様書

---

## 0. この要件定義書は何か（位置づけ）
この文書は、すでに作成した **3つのAPI仕様書（第1層/第2層/第3層）** を「なぜ必要か」「何を最終的に達成すべきか」という観点から上流にまとめ直した **要件定義書**である。

- API仕様書：何をどういう形で提供するか（エンドポイント、JSON構造、レスポンスなど）
- 要件定義書（本書）：なぜそれが必要か、何を実現するためか、どんな状態になれば成功か

つまり本書は「仕様書を書く理由」と「仕様書に含めた各要素の最終目的」を言語化し、今後の実装・運用・実験の判断基準を固定するための文書である。

---

## 1. 何がしたくてこの仕様書群を作ったのか（目的）
### 1.1 最終目的（ゴール）
Cryptomeria-coreの実験・運用において、これまで人手で行っていた以下を **BFF経由のAPI呼び出しだけで再現可能にする**ことがゴールである。

- k8s上で cryptomeria を導入し（helm）
- システムを “実験可能状態” に初期化して（relayer init / IBC connect / relayer start）
- 状態を確認し（pods/services/ports/chain status）
- チェーンに対して操作や観測を行い（Tx送信、ブロック観測など）
- 実験に必要な測定・集計・負荷投入を回し（latency/TPS/バッチ）
- 最後に環境を破棄・クリーンに戻す（uninstall/clean）

この結果として、実験の手順や運用の手順は **(a) 再現可能**で、**(b) 自動化しやすく**、**(c) 失敗時の原因が追える**ものになることを狙っている。

### 1.2 直接の課題（現状の痛点）
本仕様書群は、次の痛点の解消を狙っている。

1) **起動手順が「helmだけでは完結しない」**  
   cryptomeriaは helm install の後に、relayer init / connect / start が必要で、現状は `just start-system` や shell/kubectl exec に依存している。  
   → 実験者が毎回手順を再現する必要があり、ミス・抜け・環境差が出やすい。

2) **状態確認が散らばっている**  
   pod確認、service/port確認、relayerログ、チェーンstatusなどが `kubectl` / curl / just に分散。  
   → “今どこが悪いか” が分かりづらい。特に失敗時の切り分けが重い。

3) **実験の測定・集計がクライアント実装に寄りすぎる**  
   ブロック時間、Tx確認時間、TPS近似など、実験で必要な値が「その場のスクリプト」に埋め込まれやすい。  
   → 再実験や比較が難しく、再現性が落ちる。

4) **スケール・再接続が面倒**  
   fdscを増やすたびに helm upgrade → relayer再起動 → 接続再整備が必要。  
   → ルーチンなのに人手が介在してコストが高い。

これらを根本的に解消するには、単に「チェーンを叩けるAPI」だけでは不十分で、**k8s運用・接続手順・測定集計までをAPIとして固定する**必要があった。

---

## 2. なぜこの仕様書の内容が必要だったのか（必要性の根拠）
仕様書を3層に分けたのは、要件が混ざると “責務が曖昧になって破綻する” からである。

### 2.1 第1層（System/K8s）が必要だった理由
- cryptomeriaは **「システムを起動しただけ」では使えない**  
  helm installだけでは IBC接続やrelayer起動が完了せず、実験可能状態にならない。
- したがって “起動→実験可能状態” を保証するAPIが必要  
  そのために `start-system` 相当を **非同期ジョブ**としてAPI化する必要がある。
- さらに、Pod/Service/Portの可視化ができないと失敗時に詰む  
  startが失敗した時、何が原因かを追うために `status/ports/logs` が必須。

第1層がもたらすべき価値は、
- **人手手順（just/shell/kubectl）をAPIに置き換える**
- **“起動済み” ではなく “実験可能” を作る**
- **失敗をログとステップで説明できる**
である。

### 2.2 第2層（Blockchain）が必要だった理由
- 実験は「チェーン内部の状態とTx」を扱う  
  つまり観測（status/block/tx）と操作（simulate/broadcast）が基盤になる。
- ただし接続先（rpc/api/grpc）は環境で変わる  
  NodePortや内部DNSなど、環境差を吸収する “chain discovery” が必要。
- 卒研・実験に必要な測定は、単純なTx送信だけでなく、  
  **ブロック時間**や**ブロック内Tx一覧**のような「観測API」が必要になる。

第2層がもたらすべき価値は、
- **実験コードが「どのチェーンのどこに接続すべきか」を迷わない**
- **観測・Tx操作が統一された形で提供される**
- **実験指標（blocktime等）を取れる土台を作る**
である。

### 2.3 第3層（Utilities）が必要だった理由
- 実験の多くは「単発API呼び出し」ではなく「手順の塊」になる  
  例：Tx送信を1000件 → 確認待ち → latency集計 → TPS近似 → 状態スナップショット
- これをクライアント側に毎回実装すると、比較不能・再現不能になりやすい  
  そこで測定・集計・バッチ投入を BFF側のユーティリティとして固定する。
- 最終的に “実験結果の意味” を担保するためには、  
  実験時点の状態（pods/services/ports/chains）を記録できる必要がある  
  → resource-snapshot が必要。

第3層がもたらすべき価値は、
- **実験ロジックの共通化（測定・集計・負荷投入）**
- **再現性の高い実験結果（スナップショット付与）**
- **比較可能な指標の提供（latency/TPS/blocktime）**
である。

---

## 3. つまり仕様書の各内容は最終的に何をもたらせば良いのか（成功条件）
ここでは3層それぞれについて「最終的に達成されるべき状態」を成功条件として定義する。

### 3.1 第1層（System/K8s）の成功条件
**A. 実験可能状態を作れる**
- helm install 済みの環境に対して `POST /system/start` を叩けば、
  - relayer init
  - connect-all（IBC linkや登録）
  - relayer start
  - IBC ready の確認  
  が “ジョブとして” 進み、完了状態（succeeded/failed）が残る。

**B. 失敗を説明できる**
- `GET /system/jobs/{jobId}` で、どのステップで失敗したかが分かる。
- `GET /system/jobs/{jobId}/logs` で、実行コマンドと出力が追える。

**C. 状態を一括で確認できる**
- `GET /system/status` と `GET /system/ports` により、
  - どのPod/Service/portで何が動いているか
  - relayerは動いているか
  - チェーンは動いているか  
  が “kubectlなしで” 分かる。

> 第1層の最終価値：  
> **“cryptomeriaを動かせる人” を増やす。手順をAPIに閉じ込め、実験準備を高速化する。**

---

### 3.2 第2層（Blockchain）の成功条件
**A. チェーン発見と接続先解決ができる**
- `GET /chains` で chainIdとendpointsが取れるため、環境ごとの接続先差を吸収できる。

**B. 観測と操作が最低限揃っている**
- status/info/block/tx/account/balance が取れる
- simulate/broadcast ができる

**C. 卒研・実験のための観測が取れる**
- `blocktime` と `blocks/{h}/txs` があり、blocktime/TPS等の算出が可能。

> 第2層の最終価値：  
> **実験が「チェーンに対する統一されたAPI」を前提に書けるようになる。**

---

### 3.3 第3層（Utilities）の成功条件
**A. 実験でよく使う“手順”がAPI化されている**
- confirmation待ち、latency統計、broadcastバッチ、confirmバッチが揃う。

**B. 指標が比較可能な形で返る**
- mean/p50/p95などの統計が統一フォーマットで返る。
- throughput（TPS近似）が安定して取得できる。

**C. 実験結果に“状況証拠”が付く**
- `resource-snapshot` を実験ログに添付できることで、後から
  - どんな構成で
  - どんな状態だったか  
  を説明できる。

> 第3層の最終価値：  
> **測定・集計の実装を毎回作らずに済み、実験結果の再現性と比較可能性が上がる。**

---

## 4. 非機能要件（この仕様が成立するための条件）
本仕様書群が実際に “価値を出す” ために、APIそのものの正しさ以外に必要な条件をまとめる。

### 4.1 冪等性（再実行可能性）
- 第1層のstart/connect/scaleは、途中失敗後に再実行できる必要がある。
- `force=false` で安全側（既存ならskip）を基本とする。

### 4.2 進捗とログ（可観測性）
- ジョブはステップ単位の状態を持つこと（queued/running/succeeded/failed）
- ログは「何を実行し、何が返ったか」が追える形式で保持すること

### 4.3 負荷制御（安全運用）
- Utilities層の並列系（broadcast/confirm）は concurrency 上限をサーバ側で必ず持つ。
- blocktime/throughput等の重い観測は window 上限やキャッシュを持つ。

### 4.4 再現性（実験の品質）
- snapshotで環境状態を残せること
- 指標計算（blocktime/latency/TPS）が “いつも同じ定義” で算出されること

---

## 5. 仕様策定方針（なぜこう設計するか）
### 5.1 3層分離の意義
- 第1層：環境・運用（k8s/helm/exec） → “実験可能状態を作る”
- 第2層：チェーン内部（RPC/REST/gRPC） → “観測とTx操作”
- 第3層：実験ユースケース（測定・集計・負荷） → “実験を回す”

この分離により、
- 変更の影響範囲が限定される（k8s変更がTx APIに直撃しない）
- 実装と運用が整理される（責務の混線を防ぐ）
- 実験コード側が依存するAPIが安定する（Utilitiesの返却が固定される）

### 5.2 「仕様は長くなるほど価値がある」部分と「分割する」理由
- JSON構造やレスポンス、エラー、パラメータ範囲は、実装と実験の “ズレ” を減らすために詳細化が必要。
- しかし全層を1つの文書にすると追えなくなる。  
  → 層ごとに仕様書を分割し、本書（要件定義書）で目的と整合性を担保する。

---

## 6. 本要件が満たされたときに得られる最終成果
この要件を満たすと、最終的に次が実現できる。

1) **実験準備がAPIで固定化され、手順ミスが減る**
2) **環境差（接続先、NodePortなど）をBFFが吸収する**
3) **失敗時に “どこで何が起きたか” がジョブで追える**
4) **測定値が統一定義で取得でき、比較可能な実験ができる**
5) **実験ログに状態スナップショットを残せ、再現性が上がる**

---

## 7. スコープ（明確に “やらない” こと）
- BFF側での認証・権限・管理者トークン等は扱わない（要件から撤廃）
- ブロックチェーン研究上の新規機能（プロトコル変更等）は本要件外  
  本要件は “運用・実験・観測のAPI化” にフォーカスする
- 実験シナリオ実行（`/utils/experiments/run`）は将来枠であり、必須ではない（必要になった段階で具体化）

---

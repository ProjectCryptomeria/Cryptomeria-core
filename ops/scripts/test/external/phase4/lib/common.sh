#!/bin/bash
# ops/scripts/test/external/phase4/lib/common.sh

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
source "$(dirname "${BASH_SOURCE[0]}")/../../../../lib/common.sh"

# å®šæ•°
GWC_POD=$(get_chain_pod_name "gwc")
RELAYER_POD=$(kubectl get pod -n "$NAMESPACE" -l "app.kubernetes.io/component=relayer" -o jsonpath="{.items[0].metadata.name}")
LOG_FILE="/home/relayer/.relayer/relayer.log"
MDSC_POD=$(get_chain_pod_name "mdsc")

# =============================================================================
# ğŸ› ï¸ Helper Functions
# =============================================================================

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ (HTML)
create_html_file() {
    local filepath=$1
    local title=$2
    echo "<!DOCTYPE html><html><head><title>$title</title></head><body><h1>Hello $title</h1><p>Random: $RANDOM</p></body></html>" > "$filepath"
}

# ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®— (md5sum)
calc_hash() {
    local filepath=$1
    if [ ! -f "$filepath" ]; then echo "missing"; return; fi
    if command -v md5sum >/dev/null; then
        md5sum "$filepath" | awk '{print $1}'
    else
        md5 -q "$filepath"
    fi
}

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ³ãƒ†ãƒŠã«ã‚³ãƒ”ãƒ¼
push_to_gwc() {
    local src=$1
    local dst=$2 
    kubectl cp "$src" "$NAMESPACE/$GWC_POD:$dst" -c chain
}

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ & å®Œäº†å¾…æ©Ÿ (Relayerãƒ­ã‚°è¿½å¾“æ©Ÿèƒ½ä»˜ã)
upload_and_wait() {
    local file_path=$1 
    local target_chain=$2
    local timeout=180 # 1MBä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ç”¨ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·

    log_step "ğŸ“¤ Uploading $(basename "$file_path") (Content of $file_path)..."
    
    # ãƒ­ã‚°ã®èª­ã¿å‡ºã—é–‹å§‹ä½ç½®ã‚’å–å¾—
    local start_line=$(pod_exec "$RELAYER_POD" sh -c "wc -l < $LOG_FILE" || echo "0")
    local current_line=$((start_line + 1))

    # Txé€ä¿¡
    local cmd="gwcd tx gateway upload $(basename "$file_path") @$file_path --from $MILLIONAIRE_KEY --chain-id gwc -y --output json --keyring-backend test --home /home/gwc/.gwc"
    
    local res=$(pod_exec "$GWC_POD" $cmd)
    local tx_hash=$(echo "$res" | jq -r '.txhash')
    
    if [ -z "$tx_hash" ] || [ "$tx_hash" == "null" ]; then
        log_error "Upload failed: $res"
    fi
    log_info "TxHash: $tx_hash"

    log_info "â³ Waiting for IBC Acknowledgement (Streaming Relayer Logs)..."
    local success=false
    
    # ãƒ­ã‚°ç›£è¦–ãƒ«ãƒ¼ãƒ—
    for ((i=1; i<=timeout; i+=2)); do
        # å‰å›ã®ç¶šãã‹ã‚‰ãƒ­ã‚°ã‚’å–å¾—
        local new_logs=$(pod_exec "$RELAYER_POD" sh -c "tail -n +$current_line $LOG_FILE 2>/dev/null" || true)
        
        if [ -n "$new_logs" ]; then
            # å–å¾—ã—ãŸãƒ­ã‚°ã‚’è¡¨ç¤º (è‰²ä»˜ãã§Relayerãƒ­ã‚°ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ç¤º)
            echo -e "\033[0;90m$new_logs\033[0m"
            
            # æ¬¡å›ã®èª­ã¿å‡ºã—é–‹å§‹ä½ç½®ã‚’æ›´æ–°
            local line_count=$(echo "$new_logs" | wc -l)
            current_line=$((current_line + line_count))
            
            # æˆåŠŸåˆ¤å®š
            if echo "$new_logs" | grep -q "MsgAcknowledgement"; then
                success=true
                break
            fi
        fi
        
        sleep 2
    done

    if [ "$success" = false ]; then
        log_error "Timeout waiting for IBC packet relay."
    fi
    log_success "IBC Packet relayed successfully."
}

# ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ (MDSC/FDSCã®JSONç¢ºèª + ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ + ä¸­èº«è¡¨ç¤º)
verify_data() {
    local target_chain=$1
    local original_local_path=$2
    
    local fdsc_pod=$(get_chain_pod_name "$target_chain")
    log_step "ğŸ” Verifying data on $target_chain and MDSC..."

    # 1. ã‚ªãƒªã‚¸ãƒŠãƒ«æƒ…å ±ã®è¡¨ç¤º
    local orig_size=$(wc -c < "$original_local_path")
    local orig_hash=$(calc_hash "$original_local_path")
    log_info "ğŸ“„ Original File: $original_local_path"
    log_info "   - Size: $orig_size bytes"
    log_info "   - MD5:  $orig_hash"

    # 2. MDSC (Metadata) ã®ç¢ºèªã¨è¡¨ç¤º
    log_info "ğŸ“‹ [MDSC Data Structure (Manifests)]"
    local mdsc_json=$(pod_exec "$MDSC_POD" mdscd q metastore list-manifest -o json)
    echo "$mdsc_json" | jq '.'
    echo "----------------------------------------"

    # 3. FDSC (File Data) ã®ç¢ºèªã¨è¡¨ç¤º
    log_info "ğŸ“¦ [FDSC ($target_chain) Data Structure (Fragments)]"
    local fdsc_json=$(pod_exec "$fdsc_pod" fdscd q datastore list-fragment -o json)
    echo "$fdsc_json" | jq '.'
    echo "----------------------------------------"

    # æ–­ç‰‡æ•°ãƒã‚§ãƒƒã‚¯
    local frag_count=$(echo "$fdsc_json" | jq '.fragment | length')
    if [ "$frag_count" -eq 0 ]; then
        log_error "No fragments found on FDSC."
    fi

    # æœ€æ–°ã®ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    local content_base64=$(echo "$fdsc_json" | jq -r '.fragment[-1].data')

    if [ -z "$content_base64" ] || [ "$content_base64" == "null" ]; then
        log_error "Failed to extract data from fragment."
    fi

    # 4. å¾©å…ƒã¨æ¤œè¨¼
    local restored_path="/tmp/restored_$(basename "$original_local_path")"
    
    # Base64ãƒ‡ã‚³ãƒ¼ãƒ‰
    if ! echo "$content_base64" | base64 -d > "$restored_path"; then
        log_error "Base64 decode failed."
    fi

    local rest_size=$(wc -c < "$restored_path")
    local rest_hash=$(calc_hash "$restored_path")
    
    log_info "ğŸ”„ Restored File: $restored_path"
    log_info "   - Size: $rest_size bytes"
    log_info "   - MD5:  $rest_hash"

    # 5. æ¯”è¼ƒ
    if [ "$orig_hash" == "$rest_hash" ]; then
        log_success "Data Verification PASS: Hashes match ($orig_hash)"
        
        # 6. å¾©å…ƒã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ä¸­èº«ã‚’è¡¨ç¤º
        echo ""
        echo "ğŸ“ [Restored File Content Preview]"
        echo "========================================"
        
        # ç°¡æ˜“åˆ¤å®š: ãƒ†ã‚­ã‚¹ãƒˆãªã‚‰è¡¨ç¤ºã€ãƒã‚¤ãƒŠãƒªãªã‚‰ãƒ€ãƒ³ãƒ—
        local is_text=false
        if command -v file >/dev/null; then
            if file "$restored_path" | grep -q "text"; then is_text=true; fi
        else
            case "$restored_path" in
                *.html|*.txt|*.json|*.xml|*.css|*.js|*.md) is_text=true ;;
            esac
        fi

        if [ "$is_text" = true ]; then
            cat "$restored_path" | head -c 2000 # é•·ã™ãã‚‹å ´åˆã¯å…ˆé ­2000æ–‡å­—
            [ "$rest_size" -gt 2000 ] && echo "... (truncated)"
        else
            if command -v xxd >/dev/null; then
                xxd "$restored_path" | head -n 20
                echo "... (Binary data truncated)"
            elif command -v hexdump >/dev/null; then
                hexdump -C "$restored_path" | head -n 20
                echo "... (Binary data truncated)"
            else
                echo "(Binary data - Skipping text output)"
            fi
        fi
        echo ""
        echo "========================================"
        echo ""

        rm -f "$restored_path"
    else
        log_warn "âŒ Data Verification FAIL: Hash mismatch!"
        
        if command -v xxd >/dev/null; then
            echo "--- [Diff: First 128 bytes] ---"
            echo ">> Original:"
            xxd -l 128 "$original_local_path"
            echo ">> Restored:"
            xxd -l 128 "$restored_path"
            echo "-------------------------------"
        fi
        exit 1
    fi
}
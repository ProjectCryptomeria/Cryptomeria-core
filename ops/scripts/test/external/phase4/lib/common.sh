#!/bin/bash
# ops/scripts/test/external/phase4/lib/common.sh

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å…±é€šãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
source "$(dirname "${BASH_SOURCE[0]}")/../../../../lib/common.sh"

# å®šæ•°
GWC_POD=$(get_chain_pod_name "gwc")
RELAYER_POD=$(kubectl get pod -n "$NAMESPACE" -l "app.kubernetes.io/component=relayer" -o jsonpath="{.items[0].metadata.name}")
# LOG_FILEã¯å»ƒæ­¢
# LOG_FILE="/home/relayer/.relayer/relayer.log" 
MDSC_POD=$(get_chain_pod_name "mdsc")

# =============================================================================
# ğŸ› ï¸ Helper Functions
# =============================================================================

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ (HTML)
create_html_file() {
  local filepath=$1
  local title=$2
  echo "<!DOCTYPE html><html><head><title>$title</title></head><body><h1>Hello $title</h1><p>Random: $RANDOM</p></body></html>" > "$filepath"
}

# ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®— (md5sum)
calc_hash() {
  local filepath=$1
  if [ ! -f "$filepath" ]; then echo "missing"; return; fi
  if command -v md5sum >/dev/null; then
    md5sum "$filepath" | awk '{print $1}'
  else
    md5 -q "$filepath"
  fi
}

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ³ãƒ†ãƒŠã«ã‚³ãƒ”ãƒ¼
push_to_gwc() {
  local src=$1
  local dst=$2 
  kubectl cp "$src" "$NAMESPACE/$GWC_POD:$dst" -c chain
}

# æ–°ã—ã„é–¢æ•°: Txã‚’é€ä¿¡ã—ã€ãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—ã™ã‚‹
upload_and_get_txhash() {
    local file_path=$1 
    local tx_hash=""

    log_step "ğŸ“¤ Submitting Upload Tx for $(basename "$file_path")..."
    
    # Txé€ä¿¡ (ã‚¬ã‚¹è‡ªå‹•æ¨å®šã¨èª¿æ•´ã‚’ä½¿ç”¨)
    local cmd="gwcd tx gateway upload $(basename "$file_path") @$file_path --from $MILLIONAIRE_KEY --chain-id gwc -y --output json --keyring-backend test --home /home/gwc/.gwc --gas auto --gas-adjustment 1.2"
    
    # Txçµæœã‚’å–å¾—
    local res=$(pod_exec "$GWC_POD" $cmd)
    tx_hash=$(echo "$res" | jq -r '.txhash')
    
    if [ -z "$tx_hash" ] || [ "$tx_hash" == "null" ]; then
        log_error "Upload transaction failed: $res"
    fi
    log_info "TxHash: $tx_hash"
    
    # Txãƒãƒƒã‚·ãƒ¥ã‚’å‘¼ã³å‡ºã—å…ƒã«è¿”ã™
    echo "$tx_hash"
}


# æ–°ã—ã„é–¢æ•°: FDSCã¨MDSCã«ãƒ‡ãƒ¼ã‚¿ãŒæ°¸ç¶šåŒ–ã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿã™ã‚‹
wait_for_data_persistence() {
    local target_chain=$1
    local timeout=180
    local fdsc_pod=$(get_chain_pod_name "$target_chain")
    
    log_info "â³ Waiting for Data Persistence (Polling FDSC/MDSC)..."
    
    local persistence_success=false
    
    for ((i=1; i<=timeout/2; i++)); do # 2ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
        # A. FDSC (Data Fragment) ã®ç¢ºèª
        # Datastoreã«æ–­ç‰‡ãŒ1ã¤ã§ã‚‚ã‚ã‚Œã°OKã¨ã™ã‚‹ (ãƒãƒ£ãƒ³ã‚¯ã®æ•°ã«é–¢ä¿‚ãªã)
        local fdsc_count=$(pod_exec "$fdsc_pod" fdscd q datastore list-fragment -o json 2>/dev/null | jq '.fragment | length' 2>/dev/null || echo "0")
        
        # B. MDSC (Metadata Manifest) ã®ç¢ºèª
        # Metastoreã«ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãŒ1ã¤ã§ã‚‚ã‚ã‚Œã°OKã¨ã™ã‚‹
        local mdsc_count=$(pod_exec "$MDSC_POD" mdscd q metastore list-manifest -o json 2>/dev/null | jq '.manifest | length' 2>/dev/null || echo "0")
        
        if [ "$fdsc_count" -gt 0 ] && [ "$mdsc_count" -gt 0 ]; then
            log_success "Data Persistence Confirmed! (Fragments: $fdsc_count, Manifests: $mdsc_count)"
            persistence_success=true
            break
        fi

        echo -n "."
        sleep 2
    done
    
    if [ "$persistence_success" = false ]; then
        log_error "Timeout waiting for data persistence on storage nodes."
    fi
}


# ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ (MDSC/FDSCã®JSONç¢ºèª + ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ + ä¸­èº«è¡¨ç¤º)
verify_data() {
  local target_chain=$1
  local original_local_path=$2
  
  local fdsc_pod=$(get_chain_pod_name "$target_chain")
  log_step "ğŸ” Verifying data on $target_chain and MDSC..."

  # 1. ã‚ªãƒªã‚¸ãƒŠãƒ«æƒ…å ±ã®è¡¨ç¤º
  local orig_size=$(wc -c < "$original_local_path")
  local orig_hash=$(calc_hash "$original_local_path")
  log_info "ğŸ“„ Original File: $original_local_path"
  log_info "  - Size: $orig_size bytes"
  log_info "  - MD5: $orig_hash"

  # 2. MDSC (Metadata) ã®ç¢ºèªã¨è¡¨ç¤º
  log_info "ğŸ“‹ [MDSC Data Structure (Manifests)]"
  local mdsc_json=$(pod_exec "$MDSC_POD" mdscd q metastore list-manifest -o json)
  echo "$mdsc_json" | jq '.'
  echo "----------------------------------------"
  
  # 3. å¾©å…ƒå‡¦ç†
  log_info "ğŸ”„ Reconstructing file from fragments..."
  local restored_path="/tmp/restored_$(basename "$original_local_path")"
  local all_content_base64=""
  
  # A. ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‹ã‚‰ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆIDãƒªã‚¹ãƒˆã‚’å–å¾—
  # ãƒ•ã‚¡ã‚¤ãƒ«åãŒ index.html ã§ã‚ã‚‹ã¨ä»®å®š
  local fragment_ids=$(echo "$mdsc_json" | jq -r '.manifest[0].files["index.html"].fragments[].fragment_id')
  
  if [ -z "$fragment_ids" ]; then
    log_error "Failed to retrieve fragment IDs from MDSC manifest."
  fi
  
  # B. å„ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆIDã‚’ä½¿ã£ã¦FDSCã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€é€£çµ
  local fdsc_bin=$(get_chain_bin_name "$target_chain")
  local fragment_index=0
  
  for frag_id in $fragment_ids; do
    log_info "   - Fetching Fragment $fragment_index (ID: $frag_id)..."
    
    # FDSCã‹ã‚‰ç‰¹å®šIDã®ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— (fdscd q datastore fragment $frag_id -o json)
    local frag_data_json=$(pod_exec "$fdsc_pod" "$fdsc_bin" q datastore fragment "$frag_id" -o json 2>/dev/null)
    
    # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’æŠ½å‡º
    local content_base64=$(echo "$frag_data_json" | jq -r '.fragment.data')
    
    if [ -z "$content_base64" ] || [ "$content_base64" == "null" ]; then
      log_error "Failed to extract data for Fragment ID $frag_id."
    fi
    
    # å…¨ã¦ã®Base64æ–‡å­—åˆ—ã‚’é€£çµ
    all_content_base64+="$content_base64"
    fragment_index=$((fragment_index + 1))
  done
  
  # C. å…¨ã¦ã®Base64ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
  if ! echo "$all_content_base64" | base64 -d > "$restored_path"; then
    log_error "Combined Base64 decode failed."
  fi

  local rest_size=$(wc -c < "$restored_path")
  local rest_hash=$(calc_hash "$restored_path")
  
  log_info "ğŸ”„ Restored File: $restored_path"
  log_info "  - Size: $rest_size bytes"
  log_info "  - MD5: $rest_hash"

  # 4. æ¯”è¼ƒ (ä»¥ä¸‹ã€å¤‰æ›´ãªã—)
  if [ "$orig_hash" == "$rest_hash" ]; then
        log_success "Data Verification PASS: Hashes match ($orig_hash)"
        
        # 6. å¾©å…ƒã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ä¸­èº«ã‚’è¡¨ç¤º
        echo ""
        echo "ğŸ“ [Restored File Content Preview]"
        echo "========================================"
        
        # ç°¡æ˜“åˆ¤å®š: ãƒ†ã‚­ã‚¹ãƒˆãªã‚‰è¡¨ç¤ºã€ãƒã‚¤ãƒŠãƒªãªã‚‰ãƒ€ãƒ³ãƒ—
        local is_text=false
        if command -v file >/dev/null; then
            if file "$restored_path" | grep -q "text"; then is_text=true; fi
        else
            case "$restored_path" in
                *.html|*.txt|*.json|*.xml|*.css|*.js|*.md) is_text=true ;;
            esac
        fi

        if [ "$is_text" = true ]; then
            cat "$restored_path" | head -c 2000 # é•·ã™ãã‚‹å ´åˆã¯å…ˆé ­2000æ–‡å­—
            [ "$rest_size" -gt 2000 ] && echo "... (truncated)"
        else
            if command -v xxd >/dev/null; then
                xxd "$restored_path" | head -n 20
                echo "... (Binary data truncated)"
            elif command -v hexdump >/dev/null; then
                hexdump -C "$restored_path" | head -n 20
                echo "... (Binary data truncated)"
            else
                echo "(Binary data - Skipping text output)"
            fi
        fi
        echo ""
        echo "========================================"
        echo ""

        rm -f "$restored_path"
    else
        log_warn "âŒ Data Verification FAIL: Hash mismatch! (Original: $orig_hash, Restored: $rest_hash)"
        
        if command -v xxd >/dev/null; then
            echo "--- [Diff: First 128 bytes] ---"
            echo ">> Original:"
            xxd -l 128 "$original_local_path"
            echo ">> Restored:"
            xxd -l 128 "$restored_path"
            echo "-------------------------------"
        fi
        exit 1
    fi
}